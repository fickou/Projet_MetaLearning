{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Projet : Système Intelligent de Sélection de Modèles via Meta-Learning\n",
                "\n",
                "## 1. Objectif Général\n",
                "Concevoir une architecture de meta-learning capable de sélectionner dynamiquement le modèle de classification optimal pour détecter l’occupation d’une salle à partir de mesures environnementales."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import os\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
                "\n",
                "# Configuration\n",
                "DATA_DIR = '../data'\n",
                "MODELS_DIR = '../models'\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Chargement des Données"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading data...\n",
                        "Train shape: (8143, 7)\n",
                        "Val shape: (2665, 7)\n",
                        "Test shape: (9752, 7)\n"
                    ]
                }
            ],
            "source": [
                "def load_data(filename):\n",
                "    path = os.path.join(DATA_DIR, filename)\n",
                "    df = pd.read_csv(path)\n",
                "    return df\n",
                "\n",
                "print(\"Loading data...\")\n",
                "train_df = load_data('datatraining.txt')\n",
                "val_df = load_data('datatest.txt')\n",
                "test_df = load_data('datatest2.txt')\n",
                "\n",
                "print(f\"Train shape: {train_df.shape}\")\n",
                "print(f\"Val shape: {val_df.shape}\")\n",
                "print(f\"Test shape: {test_df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prétraitement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Preprocessing...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "['../models/scaler.joblib']"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "feature_cols = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']\n",
                "target_col = 'Occupancy'\n",
                "\n",
                "X_train = train_df[feature_cols]\n",
                "y_train = train_df[target_col]\n",
                "\n",
                "X_val = val_df[feature_cols]\n",
                "y_val = val_df[target_col]\n",
                "\n",
                "X_test = test_df[feature_cols]\n",
                "y_test = test_df[target_col]\n",
                "\n",
                "print(\"Preprocessing...\")\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# Save scaler\n",
                "joblib.dump(scaler, os.path.join(MODELS_DIR, 'scaler.joblib'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Entraînement des Classifieurs de Base (Niveau 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Base Classifiers...\n",
                        "DT Validation Accuracy: 0.9069\n",
                        "RF Validation Accuracy: 0.9535\n",
                        "SVM Validation Accuracy: 0.9700\n",
                        "NB Validation Accuracy: 0.9775\n"
                    ]
                }
            ],
            "source": [
                "print(\"Training Base Classifiers...\")\n",
                "models = {\n",
                "    'DT': DecisionTreeClassifier(random_state=42),\n",
                "    'RF': RandomForestClassifier(random_state=42),\n",
                "    'SVM': SVC(probability=True, random_state=42),\n",
                "    'NB': GaussianNB()\n",
                "}\n",
                "\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    joblib.dump(model, os.path.join(MODELS_DIR, f'{name}.joblib'))\n",
                "    acc = model.score(X_val_scaled, y_val)\n",
                "    print(f\"{name} Validation Accuracy: {acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Meta-Learning (Niveau 2)\n",
                "Extraction des méta-features (Confiance Max et Margin) et entraînement du méta-modèle KNN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting Meta-Features for Validation Set...\n",
                        "Training Meta-Model (KNN)...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "['../models/meta_model.joblib']"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def extract_meta_features(X, y, models):\n",
                "    meta_features = []\n",
                "    best_models = []\n",
                "    \n",
                "    # Get probabilities from all models\n",
                "    probs = {}\n",
                "    preds = {}\n",
                "    for name, model in models.items():\n",
                "        probs[name] = model.predict_proba(X)\n",
                "        preds[name] = model.predict(X)\n",
                "        \n",
                "    n_samples = X.shape[0]\n",
                "    model_names = list(models.keys())\n",
                "    \n",
                "    for i in range(n_samples):\n",
                "        row_meta = []\n",
                "        max_conf_correct = -1\n",
                "        best_model_idx = -1\n",
                "        \n",
                "        for idx, name in enumerate(model_names):\n",
                "            p = probs[name][i]\n",
                "            # Meta-feature 1: Max Confidence\n",
                "            conf_max = np.max(p)\n",
                "            # Meta-feature 2: Margin\n",
                "            margin = abs(p[0] - p[1])\n",
                "            \n",
                "            row_meta.extend([conf_max, margin])\n",
                "            \n",
                "            # Determine if this model is correct\n",
                "            if y is not None:\n",
                "                is_correct = (preds[name][i] == y.iloc[i])\n",
                "                if is_correct:\n",
                "                    if conf_max > max_conf_correct:\n",
                "                        max_conf_correct = conf_max\n",
                "                        best_model_idx = idx\n",
                "        \n",
                "        # Fallback\n",
                "        if y is not None and best_model_idx == -1:\n",
                "            max_conf = -1\n",
                "            for idx, name in enumerate(model_names):\n",
                "                conf = np.max(probs[name][i])\n",
                "                if conf > max_conf:\n",
                "                    max_conf = conf\n",
                "                    best_model_idx = idx\n",
                "                    \n",
                "        meta_features.append(row_meta)\n",
                "        if y is not None:\n",
                "            best_models.append(best_model_idx)\n",
                "            \n",
                "    return np.array(meta_features), np.array(best_models) if y is not None else None\n",
                "\n",
                "print(\"Extracting Meta-Features for Validation Set...\")\n",
                "X_meta_train, y_meta_train = extract_meta_features(X_val_scaled, y_val, models)\n",
                "\n",
                "print(\"Training Meta-Model (KNN)...\")\n",
                "meta_model = KNeighborsClassifier(n_neighbors=5)\n",
                "meta_model.fit(X_meta_train, y_meta_train)\n",
                "joblib.dump(meta_model, os.path.join(MODELS_DIR, 'meta_model.joblib'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Évaluation Finale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Evaluating on Test Set...\n",
                        "\n",
                        "--- Final Evaluation ---\n",
                        "Accuracy: 0.9537\n",
                        "Precision: 0.8570\n",
                        "Recall: 0.9356\n",
                        "F1 Score: 0.8945\n",
                        "Confusion Matrix:\n",
                        "[[7383  320]\n",
                        " [ 132 1917]]\n",
                        "\n",
                        "--- Individual Models on Test Set ---\n",
                        "DT: 0.9475\n",
                        "RF: 0.9722\n",
                        "SVM: 0.9531\n",
                        "NB: 0.9869\n"
                    ]
                }
            ],
            "source": [
                "print(\"Evaluating on Test Set...\")\n",
                "X_meta_test, _ = extract_meta_features(X_test_scaled, None, models)\n",
                "\n",
                "# Predict which model to use\n",
                "selected_model_indices = meta_model.predict(X_meta_test)\n",
                "\n",
                "final_predictions = []\n",
                "model_names = list(models.keys())\n",
                "\n",
                "# Get predictions from all models on test set\n",
                "test_preds_all = {}\n",
                "for name, model in models.items():\n",
                "    test_preds_all[name] = model.predict(X_test_scaled)\n",
                "\n",
                "for i, model_idx in enumerate(selected_model_indices):\n",
                "    model_name = model_names[model_idx]\n",
                "    pred = test_preds_all[model_name][i]\n",
                "    final_predictions.append(pred)\n",
                "\n",
                "final_predictions = np.array(final_predictions)\n",
                "\n",
                "# Metrics\n",
                "print(\"\\n--- Final Evaluation ---\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, final_predictions):.4f}\")\n",
                "print(f\"Precision: {precision_score(y_test, final_predictions):.4f}\")\n",
                "print(f\"Recall: {recall_score(y_test, final_predictions):.4f}\")\n",
                "print(f\"F1 Score: {f1_score(y_test, final_predictions):.4f}\")\n",
                "print(\"Confusion Matrix:\")\n",
                "print(confusion_matrix(y_test, final_predictions))\n",
                "\n",
                "# Compare with individual models\n",
                "print(\"\\n--- Individual Models on Test Set ---\")\n",
                "for name, model in models.items():\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    print(f\"{name}: {acc:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Mg4_IA",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
